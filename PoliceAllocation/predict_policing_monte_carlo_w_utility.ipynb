{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from predict_policing_agent import PredictivePolicingAgent, PredictivePolicingAgentParams\n",
    "from predict_policing_env import PredictivePolicingEnv\n",
    "import predict_policing_env\n",
    "from predict_hotspot_seppR_model import predict_hotspot_SEPP_R_model, get_bogota_mask\n",
    "from predict_policing_simulation import *\n",
    "import predict_policing_fairness_metrics \n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.getcwd() + '/../')\n",
    "import vanilla_monte_carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data_path = \"data/real_bogota_victim_data_v21_ts2555.csv\"\n",
    "model_param_path = \"output/version_21/learned_parameters/learned_parameters_thinning_FALSE.csv\"\n",
    "N_related_days = 190 # non thinned\n",
    "cells_mask_path = \"metadata/bogota_mask_1.csv\"\n",
    "gt_50hotspot_num_path = \"output/version_21/gt_int_hotspot_num.csv\"\n",
    "gt_50hotspot_num = pd.read_csv(gt_50hotspot_num_path, index_col=0)\n",
    "gt_real_hot_spots_path = \"output/version_21/gt_real_hot_spot_cells.pkl\"\n",
    "start_ts = 2000\n",
    "num_steps = 400\n",
    "\n",
    "init_params = {'crime_data_path': crime_data_path,\n",
    "                'model_param_path': model_param_path,\n",
    "                'cells_mask_path': cells_mask_path,\n",
    "                'gt_real_hot_spots_path': gt_real_hot_spots_path,\n",
    "                'start_ts': start_ts,\n",
    "                'gt_n_hot_spots': gt_50hotspot_num,\n",
    "                'n_related_days': N_related_days,\n",
    "                'n_time_steps': num_steps}\n",
    "\n",
    "potential_hot_spot_discover_rate = [1.0, 0.95, 0.9, 0.85, 0.8]\n",
    "potential_non_hot_spot_discover_rate = [0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2]\n",
    "potential_n_hot_spots = [50]\n",
    "potential_hot_spot_effect_size = [1, 2, 3]\n",
    "potential_rel_num_gap_threshold = [0.30]\n",
    "potential_fairness_window_size = [30]\n",
    "\n",
    "# get all possible combinations of parameters\n",
    "all_params = [potential_hot_spot_discover_rate, potential_non_hot_spot_discover_rate, potential_n_hot_spots,\n",
    "                potential_hot_spot_effect_size, potential_rel_num_gap_threshold,\n",
    "                potential_fairness_window_size]\n",
    "all_params = np.array(np.meshgrid(*all_params)).T.reshape(-1, len(all_params))\n",
    "\n",
    "all_configs = []\n",
    "for i in range(len(all_params)):\n",
    "    hot_spot_discover_rate = all_params[i][0]\n",
    "    non_hot_spot_discover_rate = all_params[i][1]\n",
    "    n_hot_spots = int(all_params[i][2])\n",
    "    hot_spot_effect_size = int(all_params[i][3])\n",
    "    rel_num_gap_threshold = all_params[i][4]\n",
    "    fairness_window_size = int(all_params[i][5]) \n",
    "    average_relative_num_gap_requirement = predict_policing_fairness_metrics.AverageRelativeNumberGap(rel_num_gap_threshold, \n",
    "                                                                                                        fairness_window_size)\n",
    "    config = PredictPolicingConfiguration(hot_spot_discover_rate, non_hot_spot_discover_rate, n_hot_spots,\n",
    "                                          hot_spot_effect_size, average_relative_num_gap_requirement)\n",
    "    all_configs.append([i, config])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 84.70347595214844 seconds\n"
     ]
    }
   ],
   "source": [
    "# create a vanilla testing object\n",
    "import multiprocessing as mp\n",
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[:1], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results_test = vanilla_test.run_testing(n_threads=8, t_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 20102.19899535179 seconds\n",
      "Total time used: 18764.706334352493 seconds\n"
     ]
    }
   ],
   "source": [
    "# create a vanilla testing object\n",
    "import multiprocessing as mp\n",
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[0:5], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results0 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/00-05_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results0, f)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[5:10], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results1 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/05-10_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results1, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 16807.7390897274 seconds\n",
      "Total time used: 16552.780429124832 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[10:15], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results2 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/10-15_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results2, f)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[15:20], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results3 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/15-20_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 20340.40075802803 seconds\n",
      "Total time used: 18773.915551185608 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[20:25], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results4 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/20-25_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results4, f)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[25:30], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results5 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/25-30_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 14522.270394563675 seconds\n",
      "Total time used: 20370.6916615963 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[30:35], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results6 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/30-35_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results6, f)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[35:40], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results7 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/35-40_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results7, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 18724.107235193253 seconds\n",
      "Total time used: 21303.8163254261 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[40:45], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results8 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/40-45_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results8, f)\n",
    "\n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[45:50], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results9 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/45-50_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results9, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 21561.779905319214 seconds\n",
      "Total time used: 22803.251734256744 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[50:55], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results10 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/50-55_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results10, f)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[55:60], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results11 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/55-60_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results11, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 17117.24264907837 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[60:65], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results12 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/60-65_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results12, f)\n",
    "    \n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[65:70], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results13 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/65-70_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results13, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used: 24567.150334358215 seconds\n",
      "Total time used: 23557.38680911064 seconds\n",
      "Total time used: 23493.958874940872 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stop_criteria = (MaxUnfairnessStopCriteria, 0.02)\n",
    "\n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[65:70], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results13 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/65-70_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results13, f)\n",
    "\n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[70:75], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results14 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/70-75_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results14, f)\n",
    "\n",
    "    vanilla_test = vanilla_monte_carlo.VanillaMonteCarloTestingSingle(all_configs[75:80], init_params, PredictivePolicingMonteCarloSimulation, stop_criteria)\n",
    "    results15 = vanilla_test.run_testing(n_threads=8, t_limit=4800)\n",
    "    with open('simulation_results/75-80_w_utility.pkl', 'wb') as f:\n",
    "        pickle.dump(results15, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feedbackloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
